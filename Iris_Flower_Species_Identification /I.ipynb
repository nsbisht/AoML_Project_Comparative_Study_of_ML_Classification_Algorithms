{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 3: Iris Flower Species Identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing, metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal Length (cm)</th>\n",
       "      <th>Sepal Width (cm)</th>\n",
       "      <th>Petal Length (cm)</th>\n",
       "      <th>Petal Width (cm)</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal Length (cm)  Sepal Width (cm)  Petal Length (cm)  Petal Width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "              Class  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load iris dataset\n",
    "features = ['Sepal Length (cm)', 'Sepal Width (cm)', 'Petal Length (cm)', 'Petal Width (cm)']\n",
    "target = ['Class']\n",
    "columns = [*features, *target]\n",
    "data = pd.read_csv('iris.csv', header=None, names=columns)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sepal Length (cm)    0\n",
       "Sepal Width (cm)     0\n",
       "Petal Length (cm)    0\n",
       "Petal Width (cm)     0\n",
       "Class                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for NaN values in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Iris-setosa        50\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "data['Class'] = data.Class.map({'Iris-versicolor' : 1, 'Iris-virginica' : 2, 'Iris-setosa': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal Length (cm)</th>\n",
       "      <th>Sepal Width (cm)</th>\n",
       "      <th>Petal Length (cm)</th>\n",
       "      <th>Petal Width (cm)</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal Length (cm)  Sepal Width (cm)  Petal Length (cm)  Petal Width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   Class  \n",
       "0      3  \n",
       "1      3  \n",
       "2      3  \n",
       "3      3  \n",
       "4      3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "# Normalize features\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "SIZE_TEST = 0.3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "lr_classifier = LogisticRegression()\n",
    "classifiers.append(lr_classifier)\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "classifiers.append(lda_classifier)\n",
    "sv_classifier = SVC()\n",
    "classifiers.append(sv_classifier)\n",
    "kn_classifier = KNeighborsClassifier()\n",
    "classifiers.append(kn_classifier)\n",
    "gnb_classifier = GaussianNB()\n",
    "classifiers.append(gnb_classifier)\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "classifiers.append(dt_classifier)\n",
    "rf_classifier = RandomForestClassifier()\n",
    "classifiers.append(rf_classifier)\n",
    "xgb_classifier = XGBClassifier(eval_metric='logloss')\n",
    "classifiers.append(xgb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Accuracy: 0.9555555555555556\n",
      "Precision: 0.9523809523809524\n",
      "Recall: 0.9523809523809524\n",
      "----\n",
      "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
      "Accuracy: 0.9777777777777777\n",
      "Precision: 0.9777777777777779\n",
      "Recall: 0.9761904761904763\n",
      "----\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "Accuracy: 0.9777777777777777\n",
      "Precision: 0.9777777777777779\n",
      "Recall: 0.9761904761904763\n",
      "----\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9299145299145298\n",
      "Recall: 0.9285714285714285\n",
      "----\n",
      "<class 'sklearn.naive_bayes.GaussianNB'>\n",
      "Accuracy: 0.9777777777777777\n",
      "Precision: 0.9777777777777779\n",
      "Recall: 0.9761904761904763\n",
      "----\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.8611111111111112\n",
      "Recall: 0.8571428571428571\n",
      "----\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.8740740740740741\n",
      "Recall: 0.8571428571428572\n",
      "----\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Accuracy: 0.9111111111111111\n",
      "Precision: 0.9097222222222222\n",
      "Recall: 0.9047619047619048\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print(type(classifier))\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(Y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(Y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", metrics.recall_score(Y_test, y_pred, average='macro'))\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_classifier = GaussianNB(priors=None, \n",
    "                            var_smoothing=1e-09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**priors** array-like of shape (n_classes,)\n",
    "Prior probabilities of the classes. If specified the priors are not adjusted according to the data.\n",
    "\n",
    "**var_smoothing** float, default=1e-9\n",
    "Portion of the largest variance of all features that is added to variances for calculation stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_classifier.fit(X_train, Y_train)\n",
    "y_pred = gnb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0]\n",
      " [ 1 13  0]\n",
      " [ 0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.93      0.96        14\n",
      "           3       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlt_classifier.fit(X_train, Y_train)\n",
    "y_pred = mlt_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  5  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.64      0.78        14\n",
      "           2       0.74      1.00      0.85        14\n",
      "           3       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.91      0.88      0.88        45\n",
      "weighted avg       0.92      0.89      0.89        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "plot_tree(dt_classifier, \n",
    "              feature_names = data.columns[0:-1],\n",
    "              filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.savefig(\"decision_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "*n_estimators*\n",
    "- The number of trees in the forest.\n",
    "\n",
    "min_impurity_split : float, default=None\n",
    "Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
    "\n",
    "bootstrap : bool, default=True\n",
    "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "random_state : int, RandomState instance or None, default=None\n",
    "Controls both the randomness of the bootstrapping of the samples used when building trees (if bootstrap=True)\n",
    "\n",
    "oob_scorebool, default=False\n",
    "Whether to use out-of-bag samples to estimate the generalization score. Only available if bootstrap=True.\n",
    "\n",
    "n_jobsint, default=None\n",
    "The number of jobs to run in parallel. fit, predict, decision_path and apply are all parallelized over the trees.\n",
    "\n",
    "warm_startbool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest.\n",
    "\n",
    "class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\n",
    "Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.\n",
    "\n",
    "Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].\n",
    "\n",
    "ccp_alphanon-negative float, default=0.0\n",
    "Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed.\n",
    "\n",
    "\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "base_estimator_DecisionTreeClassifier\n",
    "The child estimator template used to create the collection of fitted sub-estimators.\n",
    "\n",
    "estimators_list of DecisionTreeClassifier\n",
    "The collection of fitted sub-estimators.\n",
    "\n",
    "classes_ndarray of shape (n_classes,) or a list of such arrays\n",
    "The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).\n",
    "\n",
    "n_classes_int or list\n",
    "The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).\n",
    "\n",
    "n_features_int\n",
    "The number of features when fit is performed.\n",
    "\n",
    "n_outputs_int\n",
    "The number of outputs when fit is performed.\n",
    "\n",
    "feature_importances_ndarray of shape (n_features,)\n",
    "The impurity-based feature importances.\n",
    "\n",
    "oob_score_float\n",
    "Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True.\n",
    "\n",
    "oob_decision_function_ndarray of shape (n_samples, n_classes)\n",
    "Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, y_pred, average='macro'))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract single tree\n",
    "# estimator = rf_classifier.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "plot_tree(rf_classifier.estimators_[0], \n",
    "                  max_depth = 5,\n",
    "                  feature_names = data.columns[0:-1],\n",
    "                  rounded = True, \n",
    "                  precision = 2,\n",
    "                  filled = True,\n",
    "                  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "plot_tree(rf_classifier.estimators_[1], \n",
    "                  max_depth = 5,\n",
    "                  feature_names = data.columns[0:-1],\n",
    "                  rounded = True, \n",
    "                  precision = 2,\n",
    "                  filled = True,\n",
    "                  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
